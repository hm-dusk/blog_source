---
title: 大数据选型
date: 2018-09-03 21:00:49
updated: 2018-09-03 21:00:49
tags: [大数据]
comments: true
categories: 
  - 大数据
  - 选型
password: 302club
thumbnail: 'http://ot87uvd34.bkt.clouddn.com/hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/hadoop.jpg'
---
大数据框架选型
<!-- more -->
### 各个框架优缺点

| 名称                     | 优势和特点                                                   | 不足                                                         | 备注                                                         |
| :----: | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| HDFS                     | 1、高扩展、低成本、成熟的生态圈<br />2、处理超大文件（GB、TB甚至PB级别）<br />3、运行于廉价的商用机器集群上<br />4、高容错性和高可靠性（一份文件可以储存多份）<br /> | 1、不适合低延迟数据访问（访问延迟高，HBase补足）<br />2、频繁的读写会对NameNode造成很大压力（采用Kafka过渡）<br />3、不支持多用户写入和随机文件修改（只能在文件末尾进行追加操作） | 用作Hbase和Hive的物理储存                                    |
| HBase                    | 1、HDFS高延迟数据访问的一种改进方式，适合实时查询<br />2、可以提供高并发读写操作的支持<br />3、可以动态增加列，并且列为空就不存储数据，节省存储空间<br />4、可以自动切分数据，使得数据存储自动具有水平扩展功能 | 1、只支持简单的Row Key条件查询（除非和其他框架一起使用，例如：Phoenix、Hive）<br />2、不能支持Master server的故障切换，当Master宕机后，整个存储系统就会挂掉（可以使用Zookeeper进行多Master待命，当工作的Master宕机，则推选待命的Master继续工作）<br />3、只支持Java API（除非和其他框架一起使用，例如：Phoenix、Hive） | 应用场景：不断插入新的信息，而不修改。不需要复杂查询条件来查询数据<br />底层依赖HDFS来作为其物理储存（特殊情况可以使用本机文件系统） |
| Hive                     | 1、提供类SQL查询语言HQL<br />2、可扩展<br />3、避免去写MR，减少开发人员学习成本<br />4、提供统一的元数据(Meta store)管理（推荐使用MySQL储存元数据），可以和impala/spark等共享元数据 | 1、HQL表达能力有限<br />2、效率比较低，延迟较高（Hive用MR作为计算引擎，HDFS作为储存系统），自动生成的MR作业通常情况下不够智能化<br />3、调优比较困难，粒度较粗 | 应用场景：不支持实时查询，一般用作对一段时间内的数据（海量数据）进行分析查询（数据分析），日志分析，海量结构化数据离线分析等<br />底层依赖HDFS来作为其物理储存<br />可以通过Hive操作HBase数据进行计算分析，但是速度很慢<br />**元数据**包括：表名、表所属的数据库（默认是default）、表的拥有者、列、分区字段、表的类型（是否是外部表）、表的数据所在的目录等 |
| Zookeeper                | 1、配置管理（使用Zab一致性协议提供一致性），动态管理HBase、Hive等的配置信息<br />2、名字服务，提供类似DNS的方式映射主机<br />3、分布式锁（Leader Election），HBase的Master选举就是这种方式<br />4、集群管理，动态感知集群状态，对节点的新增和删除作动态处理 | 1、选举过程很慢，当Zookeeper的master宕机，选举新的master通常消耗30到120秒<br />2、性能有限，TPS（Transactions Per Second每秒传输的事务处理个数）大概一万多，单个节点平均连接数是6K，watcher是30万，吞吐似乎还可以，但是时延就没那么乐观了，特别是响应时间、网络、缓存<br />3、无法进行有效的权限控制，在大型的复杂系统里面，使用zookeeper必须自己再额外的开发一套权限控制系统，通过那套权限控制系统再访问zookeeper<br />4、API使用复杂<br />5、回调次数限制，ZK中所有Watch回调通知都是一次性的<br />6、由于性能的限制，导致的业务系统的数据不一致 | 1、HBase Master 的 HA(High Available) 解决方案<br />2、已经成为了分布式大数据框架中容错性的标准框架，几乎所有的分布式大数据相关的开源框架，都依赖于 Zookeeper 实现 HA |
| Yarn（统一资源管理系统） | 1、提高资源（内存、IO、网络、磁盘等）利用率<br />2、能够支持不同的计算框架，可以跑Hadoop、Storm、Spark程序<br />3、将资源管理和作业控制分离，减小JobTracker（整个MapReduce计算框架中的主服务）压力 | 1、各个应用无法感知集群整体资源的使用情况，只能等待上层调度推送信息<br />2、资源分配采用轮询、ResourceOffer机制（mesos)，在分配过程中使用悲观锁，并发粒度小<br />3、缺乏一种有效的竞争或优先抢占的机制 | 和Zookeeper的区别：Yarn相当于政府，负责管理机器资源的分配；Zookeeper相当于立法委员会,负责保持信息的一致 |
| Kafka                    | 1、实时性比直接将数据采集到HDFS高<br />2、可以将一条数据提供给多个接收者做不同的处理<br />3、消费点（数据读写记录）记录在Zookeeper中，有序且容易维护<br />4、可扩展、高性能，支持Batch操作 | 1、复杂性，Kafka需要Zookeeper的支持，Topic一般需要人工创建，部署和维护比一般MQ成本更高<br />2、不支持事务 | 1、可以使用Zookeeper来维护broker信息，实现HA                 |
| Spark                    | 1、MapReduce的替代方案，可以融入Hadoop生态系统（兼容HDFS、Hive和HBase等分布式储存层）<br />2、支持复杂查询。在简单的“map”及“reduce”操作之外，Spark还支持SQL查询、流式计算、机器学习和图算法<br />3、轻量级快速处理<br />4、支持多语言、社区活跃度高<br />5、可以直接对HDFS进行数据读写，支持YARN等部署模式 | 1、没有自带的分布式储存系统（可用HDFS、Hive和HBase等分布式储存层）<br />2、处理数据量太大时容易造成内存问题（一般超过1T建议使用MR）<br />3、JVM的内存overhead太大，1G的数据通常需要消耗5G的内存 | 与MapReduce的主要区别：<br />1、Spark的大部分操作都是在内存中，速度较快，而Hadoop的MapReduce系统会在每次操作之后将所有数据写回到物理存储介质上，速度较慢，为了确保在出现问题时能够完全恢复。但Spark的弹性分布式数据存储也能实现这一点。<br />2、在高级数据处理（如实时流处理和机器学习）方面，Spark的功能要胜过Hadoop MR<br />和Flink一样可以部署在Yarn上 |
| Flink                    | 1、支持增量迭代计算，具有对迭代自动优化的功能，性能优于Spark，在迭代次数增加后尤为明显<br />2、在流式计算方面支持毫秒级计算（和Storm一样），优于Spark流式处理的秒级计算 | 1、SQL的支持没有Spark好，Spark还支持对SQL的优化<br />2、社区活跃度没有Spark高 | 在流数据处理方面，Spark数据处理采用的是分批处理模式而Flink采用的是实时处理模式。Spark处理由数据块构成的RDD(弹性分布式数据集) ，而Flink能够实时处理一行又一行的数据。因此，无论进行何种设置，Spark总是会存在一定的数据迟延，而Flink不会有这种情况。 |
| Apache Beam              | 1、统一数据批处理（Batch）和流处理（Stream）编程的范式<br />2、能运行在任何可执行的引擎之上 | 1、国内社区活跃度低，网上实战资料很少，基本都是官网文档翻译<br />2、stackoverflow上仅有1156个问题，scala则有82,463个提问 | 与Spark的Scala开发库比较：<br />1、Apache Beam提供的基础函数支持不及Scala，例如排序，Beam必须构建一个二维元组才可以排序，而且只能升序<br />2、相同功能的代码量上来说，Scala远小于Apache Beam，Apache Beam开发效率相比Scala会低一点<br />3、Scala是脚本语言，代码格式比较随意，如果开发不规范，维护成本会比较高 |
|                          |                                                              |                                                              |                                                              |
|                          |                                                              |                                                              |                                                              |
|                          |                                                              |                                                              |                                                              |


### Kubernetes、Mesos以及Swarm对比


| 要比较的方面       | Kubernetes                                                   | Mesos                                                        | Swarm                                                        |
| :----: | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| 定位               | 专注于大规模容器集群管理。从Service 的角度定义微服务化的容器应用。<br/>整个框架考虑了很多生产中需要的功能，比如Proxy、ServiceDNS、LivenessProbe等，基本上不用经过二次开发就能应用到生产环境中 | 是一个分布式系统内核，将不同类型的主机组织在一起当作一台逻辑计算机。<br/>专注于资源的管理和任务调度，并不针对容器管理。Mesos上所有的应用部署都需要有专门的框架支撑，例如若要支撑Docker, 则必须安装Marathon;在安装Spark和Hadoop时需要不同的框架 | 是目前Docker社区原生支持的集群工具，它通过扩展DockerAPI,力图让用户像使用单机Docker API一样驱动整个集群 |
| 对容器的支持       | 天生针对容器和应用的云化，通过微服务的理念对容器进行服务化包装 | 支撑Docker,必须安装Marathon框架。只关注对应用层资源的管理，其余由框架完成 | 原生支持Docker,使用标准的Docker API， 任何使用Docker AP1与Docker进行通信的工具都可以无缝地和Swarm协同工作 |
| 对资源的控制       | 本身具备资源管控能力，可以控制容器对资源的调用               | Mesos将所有的主机虚拟成一个大的CPU、内存池，可以定义资源分配，也可以动态调配 | 在Swarm集群下可以设置参数或编排模板对应用进行资源限制        |
| 是否支持资源分区   | 能通过Namespace和Node进行集群分区，控制到主机、CPU和内存     | 支持资源分区，可以定义CPU、内存、磁盘等                      | 通过将集群分成具有不同属性的子集群来创建逻辑集群分区         |
| 开发成本           | 原生集成了Service Proxy 、Service DNS，在应用实例动态扩展时实时更新Proxy的转发规则。基本上没有二次开发成本，而且便于多集群的集成 | 要实现生产应用，需要增加很多功能，例如HA Proxy Service DNS等，需要自己实现集群扩展和Proxy的集成。二次开发成本高，需要专业的实施团队 | 由于对外提供完全标准的Docker API，所以只需理解Docker命令，用户就可以使用Swam集群，团队不需要有足够丰富的Linux 和分布式经验 |
| 非Docker应用的集成 | 不能实现Docker化的应用，可通过外部Service 方式集成到集群中   | 必须自行开发Framework 来集成到 Mesos中                       | 通过外部Service方式集成到集群中                              |

